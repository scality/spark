---

- name: Ensure facts directory exists
  file:
    state: directory
    path: /etc/ansible/facts.d
  delegate_to: "{{ groups['supervisor'][0] }}"
  run_once: true
  tags:
    - run::configs

- name: Add salt pillar to facts temporarily
  copy:
    src: /srv/scality/pillar/scality-common.sls
    dest: /etc/ansible/facts.d/scality-salt-pillar.yml
    remote_src: true
  delegate_to: "{{ groups['supervisor'][0] }}"
  run_once: true
  tags:
    - run::configs

- name: Gather facts from supervisor for sample config generation
  setup:
    fact_path: /etc/ansible/facts.d/
  delegate_to: "{{ groups['supervisor'][0] }}"
  run_once: true
  tags:
    - run::configs

- name: Remove pillar from facts
  file:
    state: absent
    path: /etc/ansible/facts.d/scality-salt-pillar.yml
  delegate_to: "{{ groups['supervisor'][0] }}"
  run_once: true
  tags:
    - run::configs

- name: Copy spark_start.sh
  template:
    src: start_spark.sh.j2
    dest: /usr/local/bin/start_spark.sh
    mode: 0744
  tags:
    - run::configs

- block:
    - name: Clone the spark repository into /root/spark on the spark master
      git:
        accept_hostkey: true
        dest: /root/spark
        repo: git@github.com:scality/spark.git
      when:
        - inventory_hostname in groups['sparkmaster']

    - name: Create sample config.yml
      template:
        src: config-template.yml.j2
        dest: /root/spark/scripts/config/config-SAMPLE.yml
        mode: 0644
      tags:
        - run::configs
      when:
        - inventory_hostname in groups['sparkmaster']

    - name: Login to the registry {{ master_container_image.split('/')[0] | lower }}
      community.general.docker_login:
        registry_url: "{{ master_container_image.split('/')[0] | lower }}"
        username: "{{ registry_user }}"
        password: "{{ registry_password }}"
      tags:
        - run::images

    - name: Pull {{ master_container_image }} image from registry
      container_image:
        name: "{{ item }}"
        state: present
      with_items:
        - "{{ master_container_image }}"
      when:
        - inventory_hostname in groups['sparkmaster']
      tags:
        - run::images

    - name: Pull {{ worker_container_image }} and {{ s3utils_container_image }} from registry
      container_image:
        name: "{{ item }}"
        state: present
      with_items:
        - "{{ worker_container_image }}"
        - "{{ s3utils_container_image }}"
      when:
        - inventory_hostname in groups['sparkworkers']
      tags:
        - run::images
  when: not offline_mode | bool

- block:
    - name: Ensure staging directory exists
      file:
        state: directory
        path: "{{ staging_path }}"
      tags:
        - run::staging

    - name: Extract the {{ staging_archive }} to {{ staging_path }}
      unarchive:
        remote_src: no
        src: "{{ staging_path }}{{ staging_archive }}"
        dest: "{{ staging_path }}"
        exclude: spark-repo.tar
      tags:
        - run::staging

    - name: Synchronize the repository and master tarball
      synchronize:
        src: "{{ staging_path }}{{ item }}.tar"
        dest: "{{ staging_path }}"
        state: present
      with_items:
        - "{{ master_container_image }}"
      when:
        - inventory_hostname in groups['sparkmaster']
      tags:
        - run::staging

    - name: Ensure spark config directory exists
      file:
        state: directory
        path: /root/spark/scripts/config
      tags:
        - run::configs
      when:
        - inventory_hostname in groups['sparkmaster']

    - name: Create sample config.yml
      template:
        src: config-template.yml.j2
        dest: /root/spark/scripts/config/config-SAMPLE.yml
        mode: 0644
      tags:
        - run::configs
      when:
        - inventory_hostname in groups['sparkmaster']

    - name: Load the master container
      docker_image:
        load_path: "{{ staging_path }}{{ item }}.tar"
        name: "{{ item }}"
        state: present
        source: load
      with_items:
        - "{{ master_container_image }}"
      when:
        - inventory_hostname in groups['sparkmaster']
      tags:
        - run::staging

    - name: Synchronize the worker and s3utils tarball
      synchronize:
        src: "{{ staging_path }}{{ item }}.tar"
        dest: "{{ staging_path }}"
        state: present
      with_items:
        - "{{ worker_container_image }}"
        - "{{ s3utils_container_image }}"
      when:
        - inventory_hostname in groups['sparkworker']
      tags:
        - run::staging

    - name: Load the worker and s3utils containers
      docker_image:
        load_path: "{{ staging_path }}{{ item }}.tar"
        name: "{{ item }}"
        state: present
        source: load
      with_items:
        - "{{ worker_container_image }}"
        - "{{ s3utils_container_image }}"
      when:
        - inventory_hostname in groups['sparkworker']
      tags:
        - run::staging
  when: offline_mode | bool

- name: Start the spark cluster
  shell: |
    /usr/local/bin/start_spark.sh
  tags:
    - run::cluster

