name: Create Release

on:
  workflow_dispatch:
    inputs:
      tag:
        description: Tag to be released
        required: true
      prerelease:
        description: Is the release a pre releae?
        type: boolean
        required: false
        default: false

run-name: Release ${{ inputs.tag }}

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - name: checkout git tag
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.tag }}
      - name: Create Variables
        run: |
          export image_path=spark-dev/deployment
          echo "image_path=${image_path}" >> $GITHUB_OUTPUT
          export staging_path=/var/tmp/staging/
          echo "staging_path=${staging_path}" >> $GITHUB_OUTPUT
          export staging_archive=spark-offline-archive.run
          echo "staging_archive=${staging_archive}" >> $GITHUB_OUTPUT
          echo "img=fieldreportservice" >> $GITHUB_OUTPUT
          echo "registry=registry.scality.com" >> $GITHUB_OUTPUT
          echo "image=${registry}/${image_path}" >> $GITHUB_OUTPUT
      - name: Registry Login
        uses: docker/login-action@v2.1.0
        with:
          registry: registry.scality.com
          username: ${{ secrets.REGISTRY_LOGIN }}
          password: ${{ secrets.REGISTRY_PASSWORD }}
      - name: Remove staging directory and old content
        run: |
          rm -rf /var/tmp/staging
      - name: Ensure makeself is installed
        run: |
          apt-get update
          apt install makeself
      - name: Checkout the Spark repository into the staging directory
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.tag }}
          path: /var/tmp/spark
      - name: Create Archive from Spark
        run: |
          cd /var/tmp/spark
          git archive --output=${{ env.staging_path }}spark-offline-archive.tar --format-tar HEAD
      - name: Pull containers from ${{ env.registry }}
        run: |
          docker pull ${{ env.registry }}/spark/spark-master:latest
          docker pull ${{ env.registry }}/spark/spark-worker:latest
          docker pull ${{ env.registry }}/s3utils/s3utils:1.12.5
          docker pull docker.io/library/nginx:1.21.6-alpine
      - name: Save the images into the staging directory
        run: |
          docker save -o ${{ env.staging_path }}spark/spark-master.tar ${{ env.registry }}/spark/spark-master:latest
          docker save -o ${{ env.staging_path }}spark/spark-worker.tar ${{ env.registry }}/spark/spark-worker:latest
          docker save -o ${{ env.staging_path }}spark/s3utils.tar ${{ env.registry }}/s3utils/s3utils:1.12.5
          docker save -o ${{ env.staging_path }}spark/nginx.tar docker.io/library/nginx:1.21.6-alpine
      - name: Copy the setup script into the staging directory
        run: |
          cp /var/tmp/spark/scripts/offline-archive-setup.sh ${{ env.staging_path }}
      - name: Create self extracting archive (SFX)
        run: |
          cd ${{ env.staging_path }}
          makeself \
            --nocomp \
            --notemp \
            ${{ env.staging_path }} \
            /var/tmp/${{ env.staging_archive }} \
            "Scality Spark Orphan Hunter SFX (Self Extracting Archive)" \
            ./setup.sh
      - name: Examine self extracting archive (SFX)
        run: |
          ls -l /var/tmp/${{ env.staging_archive }}
      - name: Cleanup staging temp files
        run: |
          rm -rf ${{ env.staging_path }} ${{ env.staging_path }}../spark
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          name: Release ${{ inputs.tag }}
          tag_name: ${{ inputs.tag }}
          generate_release_notes: false
          target_commitish: ${{ github.sha }}
          prerelease: ${{ inputs.prerelease }}
          files: /var/tmp/${{ env.staging_archive }}
