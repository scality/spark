name: Create Release

on:
  workflow_dispatch:
    inputs:
      tag:
        description: Tag to be released
        required: true
      prerelease:
        description: Is the release a pre releae?
        type: boolean
        required: false
        default: false

run-name: Release ${{ inputs.tag }}

jobs:
  release:
    runs-on: ubuntu-latest
    steps:
      - name: Create Variables
        run: |
          export image_path=spark-dev/deployment
          echo "image_path=${image_path}" >> $GITHUB_ENV 
          export staging_path=/home/runner/work/spark/spark/var/tmp/staging
          echo "staging_path=${staging_path}" >> $GITHUB_ENV
          export temp_path=/home/runner/work/spark/spark/var/tmp/spark
          echo "temp_path=${temp_path}" >> $GITHUB_ENV
          export staging_archive=spark-offline-archive.run
          echo "staging_archive=${staging_archive}" >> $GITHUB_ENV
          echo "registry=registry.scality.com" >> $GITHUB_ENV
          echo "img=fieldreportservice" >> $GITHUB_OUTPUT
          echo "image=${registry}/${image_path}" >> $GITHUB_OUTPUT
      - name: Make staging and temp directories
        run: |
          mkdir -pv ${{ env.staging_path }} ${{ env.temp_path }}
      - name: Checkout the Spark repository into the staging directory
        uses: actions/checkout@v3
        with:
          ref: ${{ inputs.tag }}
          path: ${{ env.temp_path }}
      - name: Registry Login
        uses: docker/login-action@v2.1.0
        with:
          registry: registry.scality.com
          username: ${{ secrets.REGISTRY_LOGIN }}
          password: ${{ secrets.REGISTRY_PASSWORD }}
      - name: Ensure makeself is installed
        run: |
          sudo apt-get update
          sudo apt-get install -y makeself
      - name: Create Archive from Spark
        run: |
          cd ${{ env.temp_path }}
          git archive --output=${{ env.staging_path }}/spark-offline-archive.tar --format=tar HEAD
      - name: Pull containers from ${{ env.registry }}
        run: |
          docker pull ${{ env.registry }}/spark/spark-master:latest
          docker pull ${{ env.registry }}/spark/spark-worker:latest
          docker pull ${{ env.registry }}/s3utils/s3utils:1.12.5
          docker pull docker.io/library/nginx:1.21.6-alpine
      - name: Save the images into the staging directory
        run: |
          docker save -o ${{ env.staging_path }}/spark/spark-master.tar ${{ env.registry }}/spark/spark-master:latest
          docker save -o ${{ env.staging_path }}/spark/spark-worker.tar ${{ env.registry }}/spark/spark-worker:latest
          docker save -o ${{ env.staging_path }}/spark/s3utils.tar ${{ env.registry }}/s3utils/s3utils:1.12.5
          docker save -o ${{ env.staging_path }}/spark/nginx.tar docker.io/library/nginx:1.21.6-alpine
      - name: Copy the setup script into the staging directory
        run: |
          cp ${{ env.temp_path }}/scripts/offline-archive-setup.sh ${{ env.staging_path }}/setup.sh
      - name: Create self extracting archive (SFX)
        run: |
          cd ${{ env.staging_path }}
          makeself \
            --nocomp \
            --notemp \
            ${{ env.staging_path }} \
            ${{ env.temp_path }}/../${{ env.staging_archive }} \
            "Scality Spark Orphan Hunter SFX (Self Extracting Archive)" \
            ./setup.sh
      - name: Examine self extracting archive (SFX)
        run: |
          ls -l ${{ env.temp_path }}/../${{ env.staging_archive }}
      - name: Cleanup staging temp files
        run: |
          rm -rf ${{ env.staging_path }} ${{ env.temp_path }}
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          name: Release ${{ inputs.tag }}
          tag_name: ${{ inputs.tag }}
          generate_release_notes: false
          target_commitish: ${{ github.sha }}
          prerelease: ${{ inputs.prerelease }}
          files: ${{ env.temp_path }}/../${{ env.staging_archive }}
